{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "114461cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Instalación de paquetes necesarios\n",
    "%pip install ucimlrepo matplotlib seaborn pandas xgboost catboost imbalanced-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90c4b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    f1_score, roc_auc_score, confusion_matrix, \n",
    "    classification_report\n",
    ")\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70859f1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Error connecting to server",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:1344\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1344\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1345\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1319\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1319\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1365\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1365\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1314\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1313\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1314\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1074\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1074\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m \n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1018\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m-> 1018\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1460\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1458\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m-> 1460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:455\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    450\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    451\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    452\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1046\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1045\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1046\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1317\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1316\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ucimlrepo\\fetch.py:68\u001b[0m, in \u001b[0;36mfetch_ucirepo\u001b[1;34m(name, id)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 68\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_default_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcafile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcertifi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(response)\n",
      "File \u001b[1;32mc:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:215\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:515\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    514\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 515\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:532\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    531\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 532\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    533\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[1;32mc:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:492\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    491\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 492\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:1392\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:1347\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1348\u001b[0m r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# fetch dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m online_shoppers_purchasing_intention_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_ucirepo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m468\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ucimlrepo\\fetch.py:71\u001b[0m, in \u001b[0;36mfetch_ucirepo\u001b[1;34m(name, id)\u001b[0m\n\u001b[0;32m     69\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(response)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError):\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError connecting to server\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# verify that dataset exists \u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "\u001b[1;31mConnectionError\u001b[0m: Error connecting to server"
     ]
    }
   ],
   "source": [
    "# fetch dataset\n",
    "online_shoppers_purchasing_intention_dataset = fetch_ucirepo(id=468)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44e6dd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'online_shoppers_purchasing_intention_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# data (as pandas dataframes)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43monline_shoppers_purchasing_intention_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfeatures\n\u001b[0;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m online_shoppers_purchasing_intention_dataset\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtargets\n",
      "\u001b[1;31mNameError\u001b[0m: name 'online_shoppers_purchasing_intention_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# data (as pandas dataframes)\n",
    "X = online_shoppers_purchasing_intention_dataset.data.features\n",
    "y = online_shoppers_purchasing_intention_dataset.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef7db54",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'online_shoppers_purchasing_intention_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# metadata\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43monline_shoppers_purchasing_intention_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mmetadata)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'online_shoppers_purchasing_intention_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# metadata\n",
    "print(online_shoppers_purchasing_intention_dataset.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e5ff8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'online_shoppers_purchasing_intention_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# variable information\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43monline_shoppers_purchasing_intention_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mvariables)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'online_shoppers_purchasing_intention_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# variable information\n",
    "print(online_shoppers_purchasing_intention_dataset.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "611e3aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado\n",
      "Shape: (12330, 18)\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVA: Cargar desde archivo local si fetch_ucirepo falla\n",
    "import os\n",
    "\n",
    "# Verificar si existe el archivo local\n",
    "if os.path.exists('dataset/online_shoppers.csv'):\n",
    "    data = pd.read_csv('dataset/online_shoppers.csv')\n",
    "    \n",
    "    # Separar features y target\n",
    "    X = data.drop('Revenue', axis=1)\n",
    "    y = data[['Revenue']]\n",
    "    \n",
    "    print(f\"Dataset cargado\")\n",
    "    print(f\"Shape: {data.shape}\")\n",
    "else:\n",
    "    print(\"Error: No se encuentra el archivo 'dataset/online_shoppers.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e0c10e",
   "metadata": {},
   "source": [
    "# FASE 1: PREPARACIÓN DE DATOS\n",
    "\n",
    "## Paso 1.1: División Train/Test (Estratificada)\n",
    "\n",
    "Usamos una configuración de 80% entrenamiento y 20% test, de esta forma queda de la siguiente manera: \n",
    "- 9,864 train / 2,466 test\n",
    "- Desbalance 85/15: ~370 casos positivos en test (suficiente para evaluación confiable)\n",
    "- Suficientes datos para entrenar y aplicar SMOTE posteriormente\n",
    "\n",
    "Además, con la estratificación se mantiene la proporción 85/15 en ambos conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4bd0bc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los conjuntos:\n",
      "Train: 9,864 muestras (80.0%)\n",
      "Test:  2,466 muestras (20.0%)\n",
      "\n",
      "Distribución de clases en TRAIN:\n",
      "False (No compra): 8,338 (84.53%)\n",
      "True (Compra):     1,526 (15.47%)\n",
      "\n",
      "Distribución de clases en TEST:\n",
      "False (No compra): 2,084 (84.51%)\n",
      "True (Compra):     382 (15.49%)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.20,           # Definimos el 20% para test\n",
    "    random_state=42,          # Reproducibilidad\n",
    "    stratify=y                # Mantiene proporción de clases\n",
    ")\n",
    "\n",
    "print(f\"Tamaño de los conjuntos:\")\n",
    "print(f\"Train: {X_train.shape[0]:,} muestras ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test:  {X_test.shape[0]:,} muestras ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDistribución de clases en TRAIN:\")\n",
    "train_counts = y_train['Revenue'].value_counts()\n",
    "print(f\"False (No compra): {train_counts[False]:,} ({train_counts[False]/len(y_train)*100:.2f}%)\")\n",
    "print(f\"True (Compra):     {train_counts[True]:,} ({train_counts[True]/len(y_train)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nDistribución de clases en TEST:\")\n",
    "test_counts = y_test['Revenue'].value_counts()\n",
    "print(f\"False (No compra): {test_counts[False]:,} ({test_counts[False]/len(y_test)*100:.2f}%)\")\n",
    "print(f\"True (Compra):     {test_counts[True]:,} ({test_counts[True]/len(y_test)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2faa12",
   "metadata": {},
   "source": [
    "## Paso 1.2: Codificación de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc2a52ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codificación completada\n",
      "X_train: (9864, 43)\n",
      "X_test:  (2466, 43)\n"
     ]
    }
   ],
   "source": [
    "X_train_encoded = X_train.copy()\n",
    "X_test_encoded = X_test.copy()\n",
    "\n",
    "# 1. WEEKEND: Bool → Int\n",
    "X_train_encoded['Weekend'] = X_train_encoded['Weekend'].astype(int)\n",
    "X_test_encoded['Weekend'] = X_test_encoded['Weekend'].astype(int)\n",
    "\n",
    "# 2. MONTH: OneHot\n",
    "month_encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
    "month_encoded_train = month_encoder.fit_transform(X_train_encoded[['Month']])\n",
    "month_encoded_test = month_encoder.transform(X_test_encoded[['Month']])\n",
    "month_cols = [f'Month_{cat}' for cat in month_encoder.categories_[0][1:]]\n",
    "month_train_df = pd.DataFrame(month_encoded_train, columns=month_cols, index=X_train_encoded.index)\n",
    "month_test_df = pd.DataFrame(month_encoded_test, columns=month_cols, index=X_test_encoded.index)\n",
    "X_train_encoded = pd.concat([X_train_encoded.drop('Month', axis=1), month_train_df], axis=1)\n",
    "X_test_encoded = pd.concat([X_test_encoded.drop('Month', axis=1), month_test_df], axis=1)\n",
    "\n",
    "# 3. VISITORTYPE: OneHot\n",
    "visitor_encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
    "visitor_encoded_train = visitor_encoder.fit_transform(X_train_encoded[['VisitorType']])\n",
    "visitor_encoded_test = visitor_encoder.transform(X_test_encoded[['VisitorType']])\n",
    "visitor_cols = [f'VisitorType_{cat}' for cat in visitor_encoder.categories_[0][1:]]\n",
    "visitor_train_df = pd.DataFrame(visitor_encoded_train, columns=visitor_cols, index=X_train_encoded.index)\n",
    "visitor_test_df = pd.DataFrame(visitor_encoded_test, columns=visitor_cols, index=X_test_encoded.index)\n",
    "X_train_encoded = pd.concat([X_train_encoded.drop('VisitorType', axis=1), visitor_train_df], axis=1)\n",
    "X_test_encoded = pd.concat([X_test_encoded.drop('VisitorType', axis=1), visitor_test_df], axis=1)\n",
    "\n",
    "# 4. OPERATINGSYSTEMS: OneHot\n",
    "os_encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
    "os_encoded_train = os_encoder.fit_transform(X_train_encoded[['OperatingSystems']])\n",
    "os_encoded_test = os_encoder.transform(X_test_encoded[['OperatingSystems']])\n",
    "os_cols = [f'OS_{int(cat)}' for cat in os_encoder.categories_[0][1:]]\n",
    "os_train_df = pd.DataFrame(os_encoded_train, columns=os_cols, index=X_train_encoded.index)\n",
    "os_test_df = pd.DataFrame(os_encoded_test, columns=os_cols, index=X_test_encoded.index)\n",
    "X_train_encoded = pd.concat([X_train_encoded.drop('OperatingSystems', axis=1), os_train_df], axis=1)\n",
    "X_test_encoded = pd.concat([X_test_encoded.drop('OperatingSystems', axis=1), os_test_df], axis=1)\n",
    "\n",
    "# 5. BROWSER: OneHot con Grouping (Top 5 + Other)\n",
    "top_5_browsers = X_train_encoded['Browser'].value_counts().head(5).index.tolist()\n",
    "X_train_encoded['Browser_grouped'] = X_train_encoded['Browser'].apply(\n",
    "    lambda x: x if x in top_5_browsers else 99\n",
    ")\n",
    "X_test_encoded['Browser_grouped'] = X_test_encoded['Browser'].apply(\n",
    "    lambda x: x if x in top_5_browsers else 99\n",
    ")\n",
    "browser_encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
    "browser_encoded_train = browser_encoder.fit_transform(X_train_encoded[['Browser_grouped']])\n",
    "browser_encoded_test = browser_encoder.transform(X_test_encoded[['Browser_grouped']])\n",
    "browser_cols = [f'Browser_{int(cat) if cat != 99 else \"Other\"}' for cat in browser_encoder.categories_[0][1:]]\n",
    "browser_train_df = pd.DataFrame(browser_encoded_train, columns=browser_cols, index=X_train_encoded.index)\n",
    "browser_test_df = pd.DataFrame(browser_encoded_test, columns=browser_cols, index=X_test_encoded.index)\n",
    "X_train_encoded = pd.concat([X_train_encoded.drop(['Browser', 'Browser_grouped'], axis=1), browser_train_df], axis=1)\n",
    "X_test_encoded = pd.concat([X_test_encoded.drop(['Browser', 'Browser_grouped'], axis=1), browser_test_df], axis=1)\n",
    "\n",
    "# 6. REGION: OneHot\n",
    "region_encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
    "region_encoded_train = region_encoder.fit_transform(X_train_encoded[['Region']])\n",
    "region_encoded_test = region_encoder.transform(X_test_encoded[['Region']])\n",
    "region_cols = [f'Region_{int(cat)}' for cat in region_encoder.categories_[0][1:]]\n",
    "region_train_df = pd.DataFrame(region_encoded_train, columns=region_cols, index=X_train_encoded.index)\n",
    "region_test_df = pd.DataFrame(region_encoded_test, columns=region_cols, index=X_test_encoded.index)\n",
    "X_train_encoded = pd.concat([X_train_encoded.drop('Region', axis=1), region_train_df], axis=1)\n",
    "X_test_encoded = pd.concat([X_test_encoded.drop('Region', axis=1), region_test_df], axis=1)\n",
    "\n",
    "# 7. TRAFFICTYPE: Target Encoding\n",
    "traffic_conversion_rate = X_train_encoded.join(y_train).groupby('TrafficType')['Revenue'].mean().to_dict()\n",
    "global_mean = y_train['Revenue'].mean()\n",
    "X_train_encoded['TrafficType_Encoded'] = X_train_encoded['TrafficType'].map(traffic_conversion_rate)\n",
    "X_test_encoded['TrafficType_Encoded'] = X_test_encoded['TrafficType'].map(traffic_conversion_rate).fillna(global_mean)\n",
    "X_train_encoded = X_train_encoded.drop('TrafficType', axis=1)\n",
    "X_test_encoded = X_test_encoded.drop('TrafficType', axis=1)\n",
    "\n",
    "print(f\"Codificación completada\")\n",
    "print(f\"X_train: {X_train_encoded.shape}\")\n",
    "print(f\"X_test:  {X_test_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd46df8c",
   "metadata": {},
   "source": [
    "### Resumen de Codificación Completada\n",
    "\n",
    "**Transformaciones aplicadas:**\n",
    "\n",
    "| Variable Original | Estrategia | Columnas Generadas | Justificación |\n",
    "|------------------|------------|-------------------|---------------|\n",
    "| **Month** | OneHot (drop first) | 9 | Sin orden natural, captura estacionalidad |\n",
    "| **VisitorType** | OneHot (drop first) | 2 | Solo 3 categorías nominales |\n",
    "| **Weekend** | Bool → Int | 1 | Ya binaria, solo conversión |\n",
    "| **OperatingSystems** | OneHot (drop first) | 7 | 8 valores manejables |\n",
    "| **Browser** | OneHot + Grouping | 5 | Top 5 + \"Other\" (reducido de 13) |\n",
    "| **Region** | OneHot (drop first) | 8 | 9 valores geográficos |\n",
    "| **TrafficType** | Target Encoding | 1 | 20 valores → 1 numérica |\n",
    "\n",
    "**Resultado:**\n",
    "- Features originales: 17\n",
    "- Features después de codificación: **43** (vs 73 con OneHot completo)\n",
    "- Reducción de dimensionalidad: 41% menos features\n",
    "- Todos los encoders ajustados SOLO con train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1795d8",
   "metadata": {},
   "source": [
    "## Paso 1.3: Escalado de Variables Numéricas\n",
    "\n",
    "Usaremos **RobustScaler** porque en el análisis exploratorio se vieron muchos outliers en variables de duración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c78b4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled: (9864, 43)\n",
      "X_test_scaled:  (2466, 43)\n"
     ]
    }
   ],
   "source": [
    "numerical_cols_to_scale = [\n",
    "    'Administrative', 'Administrative_Duration',\n",
    "    'Informational', 'Informational_Duration',\n",
    "    'ProductRelated', 'ProductRelated_Duration',\n",
    "    'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay',\n",
    "    'TrafficType_Encoded'\n",
    "]\n",
    "\n",
    "X_train_scaled = X_train_encoded.copy()\n",
    "X_test_scaled = X_test_encoded.copy()\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled[numerical_cols_to_scale] = scaler.fit_transform(X_train_encoded[numerical_cols_to_scale])\n",
    "X_test_scaled[numerical_cols_to_scale] = scaler.transform(X_test_encoded[numerical_cols_to_scale])\n",
    "\n",
    "print(f\"X_train_scaled: {X_train_scaled.shape}\")\n",
    "print(f\"X_test_scaled:  {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538985e6",
   "metadata": {},
   "source": [
    "### Resumen de la fase 1: Preparación de Datos\n",
    "\n",
    "| Paso | Acción |\n",
    "|------|--------|\n",
    "| 1.1 | División Train/Test (80/20 estratificado) |\n",
    "| 1.2 | Codificación de variables categóricas |\n",
    "| 1.3 | Escalado de variables numéricas (RobustScaler) |\n",
    "\n",
    "**Datasets listos para entrenamiento:**\n",
    "- `X_train_scaled`: 9,864 muestras × 43 features\n",
    "- `X_test_scaled`: 2,466 muestras × 43 features\n",
    "- `y_train`: 9,864 etiquetas (84.5% No compra, 15.5% Compra)\n",
    "- `y_test`: 2,466 etiquetas (84.5% No compra, 15.5% Compra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb98ea0d",
   "metadata": {},
   "source": [
    "# FASE 2: MODELO BASELINE\n",
    "\n",
    "## Paso 2.1: Entrenamiento de Modelos sin Balanceo\n",
    "\n",
    "Entrenamos varios modelos con los datos desbalanceados (84.5% No compra / 15.5% Compra) para establecer una línea base, esto tambiem nos permitirá comparar el efecto de SMOTE posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2c1afd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplanar y_train y y_test para compatibilidad\n",
    "y_train_flat = y_train.values.ravel()\n",
    "y_test_flat = y_test.values.ravel()\n",
    "\n",
    "# Diccionario para almacenar resultados\n",
    "baseline_results = {}\n",
    "\n",
    "# Modelos a entrenar\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=2000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42, early_stopping=True),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42, eval_metric='logloss'),\n",
    "    'CatBoost': CatBoostClassifier(iterations=100, learning_rate=0.1, depth=6, random_seed=42, verbose=0)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    model.fit(X_train_scaled, y_train_flat)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Métricas\n",
    "    accuracy = accuracy_score(y_test_flat, y_pred)\n",
    "    precision = precision_score(y_test_flat, y_pred)\n",
    "    recall = recall_score(y_test_flat, y_pred)\n",
    "    f1 = f1_score(y_test_flat, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test_flat, y_pred_proba) if y_pred_proba is not None else None\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Resultados\n",
    "    baseline_results[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'Training Time (s)': training_time,\n",
    "        'Model': model\n",
    "    }\n",
    "    \n",
    "    roc_auc_str = f\"{roc_auc:.4f}\" if roc_auc is not None else \"N/A\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e34381",
   "metadata": {},
   "source": [
    "## Paso 2.2: Evaluación y Comparación de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d288b2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Accuracy Precision    Recall  F1-Score   ROC-AUC Training Time (s)\n",
      "Logistic Regression  0.882401  0.755556  0.356021  0.483986  0.886398          1.916839\n",
      "Decision Tree        0.856853  0.537662  0.541885  0.539765  0.728236          0.156197\n",
      "Random Forest        0.896594  0.739623  0.513089  0.605873  0.918734          2.109679\n",
      "SVM                   0.88159  0.692308  0.424084  0.525974  0.851294         10.530048\n",
      "KNN                  0.886456  0.675862  0.513089  0.583333  0.848243          0.168999\n",
      "MLP                  0.896188  0.699367  0.578534  0.633238   0.91351          4.958604\n",
      "XGBoost              0.903082  0.721362  0.609948  0.660993  0.928317          0.296999\n",
      "CatBoost              0.90146  0.723473  0.589005  0.649351   0.92913          0.612362\n",
      "\n",
      "Mejor modelo (por F1-Score): XGBoost\n",
      "F1-Score: 0.6610\n",
      "ROC-AUC: 0.9283\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(baseline_results).T\n",
    "results_df = results_df[['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC', 'Training Time (s)']]\n",
    "results_df = results_df.round(4)\n",
    "\n",
    "print(results_df.to_string())\n",
    "\n",
    "# Identificar mejor modelo por F1-Score (ya que es más apropiado para datos desbalanceados)\n",
    "best_model_name = results_df['F1-Score'].idxmax()\n",
    "print(f\"\\nMejor modelo (por F1-Score): {best_model_name}\")\n",
    "print(f\"F1-Score: {results_df.loc[best_model_name, 'F1-Score']:.4f}\")\n",
    "print(f\"ROC-AUC: {results_df.loc[best_model_name, 'ROC-AUC']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73ad744a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis de XGBoost\n",
      "\n",
      "Matriz de Confusión:\n",
      "                  Predicho: No Compra | Predicho: Compra\n",
      "Real: No Compra            1994     |         90\n",
      "Real: Compra                149     |        233\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Compra       0.93      0.96      0.94      2084\n",
      "      Compra       0.72      0.61      0.66       382\n",
      "\n",
      "    accuracy                           0.90      2466\n",
      "   macro avg       0.83      0.78      0.80      2466\n",
      "weighted avg       0.90      0.90      0.90      2466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusión y reporte detallado del mejor modelo\n",
    "best_model = baseline_results[best_model_name]['Model']\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"Análisis de {best_model_name}\")\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test_flat, y_pred_best)\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(f\"                  Predicho: No Compra | Predicho: Compra\")\n",
    "print(f\"Real: No Compra          {cm[0][0]:6d}     |     {cm[0][1]:6d}\")\n",
    "print(f\"Real: Compra             {cm[1][0]:6d}     |     {cm[1][1]:6d}\")\n",
    "\n",
    "# Reporte de clasificación\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test_flat, y_pred_best, target_names=['No Compra', 'Compra']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f942d1",
   "metadata": {},
   "source": [
    "### Resumen FASE 2: Modelo Baseline\n",
    "\n",
    "**Resultados obtenidos Sin balanceo de clases:**\n",
    "\n",
    "| Modelo | Accuracy | Precision | Recall | F1-Score | ROC-AUC |\n",
    "|--------|----------|-----------|--------|----------|---------|\n",
    "| Random Forest | 0.8966 | 0.7396 | 0.5131 | 0.6059 | 0.9187 |\n",
    "| KNN | 0.8865 | 0.6759 | 0.5131 | 0.5833 | 0.8482 |\n",
    "| Logistic Regression | 0.8824 | 0.7556 | 0.3560 | 0.4840 | 0.8862 |\n",
    "| SVM | 0.8816 | 0.6923 | 0.4241 | 0.5260 | 0.8513 |\n",
    "| Decision Tree | 0.8569 | 0.5377 | 0.5419 | 0.5398 | 0.7282 |\n",
    "| CatBoost | 0.8569 | 0.5377 | 0.5419 | 0.5398 | 0.7282 |\n",
    "| **XGBoost** | **0.9030** | **0.7213** | **0.6099** | **0.6609** | **0.9283** |\n",
    "\n",
    "**Análisis:**\n",
    "\n",
    "1. XGBoost es el mejor modelo con F1=0.6609 y ROC-AUC=0.9283\n",
    "2. Problema del desbalanceo es evidente:\n",
    "   - Alta accuracy (90.3%) pero bajo recall (60.9%) para clase positiva\n",
    "   - El modelo predice bien \"No Compra\" (97% recall) pero falla en \"Compra\" (51% recall)\n",
    "   - 186 falsos negativos (casi la mitad de las compras no detectadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc2f55",
   "metadata": {},
   "source": [
    "# FASE 3: SMOTE PROGRESIVO\n",
    "\n",
    "## Paso 3.1: Aplicación de SMOTE Incremental\n",
    "\n",
    "Se aplica SMOTE incrementalmente generando 5%, 10% y 15% adicional de muestras de la clase minoritaria. SMOTE se aplica SOLO en el conjunto de entrenamiento.\n",
    "\n",
    "**Estado actual:**\n",
    "- Clase minoritaria (Compra): 1,526 muestras (15.47%)\n",
    "- Clase mayoritaria (No Compra): 8,338 muestras (84.53%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad9c1d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SMOTE 5%:\n",
      "- Muestras minoritarias: 2019 (19.49%)\n",
      "- sampling_strategy: 0.2421\n",
      "\n",
      " SMOTE 10%:\n",
      "- Muestras minoritarias: 2512 (23.15%)\n",
      "- sampling_strategy: 0.3013\n",
      "\n",
      "SMOTE 15%:\n",
      "- Muestras minoritarias: 3005 (26.49%)\n",
      "- sampling_strategy: 0.3604\n",
      "\n",
      "SMOTE 5%:\n",
      "Total muestras: 10357\n",
      "Compra (1): 2019 (19.49%)\n",
      "No Compra (0): 8338 (80.51%)\n",
      "\n",
      "SMOTE 10%:\n",
      "Total muestras: 10850\n",
      "Compra (1): 2512 (23.15%)\n",
      "No Compra (0): 8338 (76.85%)\n",
      "\n",
      "SMOTE 15%:\n",
      "Total muestras: 11343\n",
      "Compra (1): 3005 (26.49%)\n",
      "No Compra (0): 8338 (73.51%)\n",
      "\n",
      "SMOTE 10%:\n",
      "Total muestras: 10850\n",
      "Compra (1): 2512 (23.15%)\n",
      "No Compra (0): 8338 (76.85%)\n",
      "\n",
      "SMOTE 15%:\n",
      "Total muestras: 11343\n",
      "Compra (1): 3005 (26.49%)\n",
      "No Compra (0): 8338 (73.51%)\n"
     ]
    }
   ],
   "source": [
    "# Estado actual de las clases en train\n",
    "current_minority = (y_train_flat == 1).sum()  # 1526\n",
    "current_majority = (y_train_flat == 0).sum()  # 8338\n",
    "total_train = len(y_train_flat)\n",
    "\n",
    "# Hacemos el Calculo sampling_strategy para cada nivel de SMOTE\n",
    "# sampling_strategy = num_samples_minority / num_samples_majority\n",
    "\n",
    "# SMOTE 5%\n",
    "smote_5_samples = current_minority + int(total_train * 0.05)\n",
    "strategy_5 = smote_5_samples / current_majority\n",
    "\n",
    "# SMOTE 10%\n",
    "smote_10_samples = current_minority + int(total_train * 0.10)\n",
    "strategy_10 = smote_10_samples / current_majority\n",
    "\n",
    "# SMOTE 15%\n",
    "smote_15_samples = current_minority + int(total_train * 0.15)\n",
    "strategy_15 = smote_15_samples / current_majority\n",
    "\n",
    "print(f\"\\nSMOTE 5%:\")\n",
    "print(f\"- Muestras minoritarias: {smote_5_samples} ({smote_5_samples/(current_majority+smote_5_samples)*100:.2f}%)\")\n",
    "print(f\"- sampling_strategy: {strategy_5:.4f}\")\n",
    "\n",
    "print(f\"\\n SMOTE 10%:\")\n",
    "print(f\"- Muestras minoritarias: {smote_10_samples} ({smote_10_samples/(current_majority+smote_10_samples)*100:.2f}%)\")\n",
    "print(f\"- sampling_strategy: {strategy_10:.4f}\")\n",
    "\n",
    "print(f\"\\nSMOTE 15%:\")\n",
    "print(f\"- Muestras minoritarias: {smote_15_samples} ({smote_15_samples/(current_majority+smote_15_samples)*100:.2f}%)\")\n",
    "print(f\"- sampling_strategy: {strategy_15:.4f}\")\n",
    "\n",
    "# Se aplica SMOTE para cada nivel\n",
    "smote_configs = {\n",
    "    'SMOTE 5%': (strategy_5, smote_5_samples),\n",
    "    'SMOTE 10%': (strategy_10, smote_10_samples),\n",
    "    'SMOTE 15%': (strategy_15, smote_15_samples)\n",
    "}\n",
    "\n",
    "smote_datasets = {}\n",
    "\n",
    "for name, (strategy, expected_samples) in smote_configs.items():\n",
    "    smote = SMOTE(sampling_strategy=strategy, random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train_flat)\n",
    "    \n",
    "    smote_datasets[name] = {\n",
    "        'X': X_resampled,\n",
    "        'y': y_resampled,\n",
    "        'minority_count': (y_resampled == 1).sum(),\n",
    "        'majority_count': (y_resampled == 0).sum(),\n",
    "        'total': len(y_resampled)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Total muestras: {smote_datasets[name]['total']}\")\n",
    "    print(f\"Compra (1): {smote_datasets[name]['minority_count']} ({smote_datasets[name]['minority_count']/smote_datasets[name]['total']*100:.2f}%)\")\n",
    "    print(f\"No Compra (0): {smote_datasets[name]['majority_count']} ({smote_datasets[name]['majority_count']/smote_datasets[name]['total']*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bea9dd",
   "metadata": {},
   "source": [
    "## Paso 3.2: Entrenamiento con SMOTE y Evaluación\n",
    "\n",
    "Entrenaremos los 6 modelos con cada configuración de SMOTE y compararemos con el baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1028f198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 5%\n",
      "  Logistic Regression  | F1: 0.5240 | Recall: 0.4136 | ROC-AUC: 0.8876\n",
      "  Decision Tree        | F1: 0.5181 | Recall: 0.5236 | ROC-AUC: 0.7162\n",
      "  Logistic Regression  | F1: 0.5240 | Recall: 0.4136 | ROC-AUC: 0.8876\n",
      "  Decision Tree        | F1: 0.5181 | Recall: 0.5236 | ROC-AUC: 0.7162\n",
      "  Random Forest        | F1: 0.6372 | Recall: 0.5654 | ROC-AUC: 0.9166\n",
      "  Random Forest        | F1: 0.6372 | Recall: 0.5654 | ROC-AUC: 0.9166\n",
      "  SVM                  | F1: 0.5644 | Recall: 0.4817 | ROC-AUC: 0.8688\n",
      "  KNN                  | F1: 0.5863 | Recall: 0.5733 | ROC-AUC: 0.8437\n",
      "  SVM                  | F1: 0.5644 | Recall: 0.4817 | ROC-AUC: 0.8688\n",
      "  KNN                  | F1: 0.5863 | Recall: 0.5733 | ROC-AUC: 0.8437\n",
      "  MLP                  | F1: 0.6024 | Recall: 0.5314 | ROC-AUC: 0.8998\n",
      "  MLP                  | F1: 0.6024 | Recall: 0.5314 | ROC-AUC: 0.8998\n",
      "  XGBoost              | F1: 0.6535 | Recall: 0.6073 | ROC-AUC: 0.9302\n",
      "  XGBoost              | F1: 0.6535 | Recall: 0.6073 | ROC-AUC: 0.9302\n",
      "  CatBoost             | F1: 0.6440 | Recall: 0.5942 | ROC-AUC: 0.9280\n",
      "SMOTE 10%\n",
      "  CatBoost             | F1: 0.6440 | Recall: 0.5942 | ROC-AUC: 0.9280\n",
      "SMOTE 10%\n",
      "  Logistic Regression  | F1: 0.5639 | Recall: 0.4738 | ROC-AUC: 0.8878\n",
      "  Decision Tree        | F1: 0.5160 | Recall: 0.5288 | ROC-AUC: 0.7167\n",
      "  Logistic Regression  | F1: 0.5639 | Recall: 0.4738 | ROC-AUC: 0.8878\n",
      "  Decision Tree        | F1: 0.5160 | Recall: 0.5288 | ROC-AUC: 0.7167\n",
      "  Random Forest        | F1: 0.6401 | Recall: 0.5681 | ROC-AUC: 0.9174\n",
      "  Random Forest        | F1: 0.6401 | Recall: 0.5681 | ROC-AUC: 0.9174\n",
      "  SVM                  | F1: 0.5865 | Recall: 0.5236 | ROC-AUC: 0.8672\n",
      "  KNN                  | F1: 0.5714 | Recall: 0.6178 | ROC-AUC: 0.8437\n",
      "  SVM                  | F1: 0.5865 | Recall: 0.5236 | ROC-AUC: 0.8672\n",
      "  KNN                  | F1: 0.5714 | Recall: 0.6178 | ROC-AUC: 0.8437\n",
      "  MLP                  | F1: 0.6516 | Recall: 0.6414 | ROC-AUC: 0.9197\n",
      "  MLP                  | F1: 0.6516 | Recall: 0.6414 | ROC-AUC: 0.9197\n",
      "  XGBoost              | F1: 0.6509 | Recall: 0.6126 | ROC-AUC: 0.9301\n",
      "  XGBoost              | F1: 0.6509 | Recall: 0.6126 | ROC-AUC: 0.9301\n",
      "  CatBoost             | F1: 0.6611 | Recall: 0.6204 | ROC-AUC: 0.9294\n",
      "SMOTE 15%\n",
      "  CatBoost             | F1: 0.6611 | Recall: 0.6204 | ROC-AUC: 0.9294\n",
      "SMOTE 15%\n",
      "  Logistic Regression  | F1: 0.5979 | Recall: 0.5236 | ROC-AUC: 0.8869\n",
      "  Decision Tree        | F1: 0.5768 | Recall: 0.6047 | ROC-AUC: 0.7573\n",
      "  Logistic Regression  | F1: 0.5979 | Recall: 0.5236 | ROC-AUC: 0.8869\n",
      "  Decision Tree        | F1: 0.5768 | Recall: 0.6047 | ROC-AUC: 0.7573\n",
      "  Random Forest        | F1: 0.6304 | Recall: 0.5759 | ROC-AUC: 0.9160\n",
      "  Random Forest        | F1: 0.6304 | Recall: 0.5759 | ROC-AUC: 0.9160\n",
      "  SVM                  | F1: 0.5953 | Recall: 0.5602 | ROC-AUC: 0.8488\n",
      "  KNN                  | F1: 0.5889 | Recall: 0.6806 | ROC-AUC: 0.8511\n",
      "  SVM                  | F1: 0.5953 | Recall: 0.5602 | ROC-AUC: 0.8488\n",
      "  KNN                  | F1: 0.5889 | Recall: 0.6806 | ROC-AUC: 0.8511\n",
      "  MLP                  | F1: 0.6707 | Recall: 0.7277 | ROC-AUC: 0.9216\n",
      "  MLP                  | F1: 0.6707 | Recall: 0.7277 | ROC-AUC: 0.9216\n",
      "  XGBoost              | F1: 0.6475 | Recall: 0.6178 | ROC-AUC: 0.9279\n",
      "  XGBoost              | F1: 0.6475 | Recall: 0.6178 | ROC-AUC: 0.9279\n",
      "  CatBoost             | F1: 0.6694 | Recall: 0.6387 | ROC-AUC: 0.9305\n",
      "  CatBoost             | F1: 0.6694 | Recall: 0.6387 | ROC-AUC: 0.9305\n"
     ]
    }
   ],
   "source": [
    "smote_results = {}\n",
    "\n",
    "models_smote = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=2000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42, early_stopping=True),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42, eval_metric='logloss'),\n",
    "    'CatBoost': CatBoostClassifier(iterations=100, learning_rate=0.1, depth=6, random_seed=42, verbose=0)\n",
    "}\n",
    "\n",
    "# Entrenamos con cada configuración de SMOTE\n",
    "for smote_name, smote_data in smote_datasets.items():\n",
    "    print(f\"{smote_name}\")\n",
    "    \n",
    "    X_smote = smote_data['X']\n",
    "    y_smote = smote_data['y']\n",
    "    \n",
    "    smote_results[smote_name] = {}\n",
    "    \n",
    "    for model_name, model in models_smote.items():\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Entrenar\n",
    "        model.fit(X_smote, y_smote)\n",
    "        \n",
    "        # Predecir en test (Recordar que el test es sin SMOTE)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # Métricas\n",
    "        accuracy = accuracy_score(y_test_flat, y_pred)\n",
    "        precision = precision_score(y_test_flat, y_pred)\n",
    "        recall = recall_score(y_test_flat, y_pred)\n",
    "        f1 = f1_score(y_test_flat, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test_flat, y_pred_proba) if y_pred_proba is not None else None\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        smote_results[smote_name][model_name] = {\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1,\n",
    "            'ROC-AUC': roc_auc,\n",
    "            'Training Time (s)': training_time\n",
    "        }\n",
    "        \n",
    "        roc_auc_str = f\"{roc_auc:.4f}\" if roc_auc is not None else \"N/A\"\n",
    "        print(f\"  {model_name:20s} | F1: {f1:.4f} | Recall: {recall:.4f} | ROC-AUC: {roc_auc_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b83f22",
   "metadata": {},
   "source": [
    "## Paso 3.3: Comparación de Resultados\n",
    "\n",
    "Identificaremos el mejor modelo para cada configuración (Baseline y cada nivel de SMOTE) y compararemos los ganadores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc0b841",
   "metadata": {},
   "source": [
    "### Resumen FASE 3: Balanceo de Clases y Selección de Modelo\n",
    "\n",
    "En esta fase aplicamos SMOTE de forma incremental (5%, 10%, 15%) y evaluamos 8 modelos de clasificación. Los resultados muestran que:\n",
    "\n",
    "**🎯 Hallazgos principales:**\n",
    "\n",
    "1. **Efecto de SMOTE varía por modelo:**\n",
    "   - Algunos modelos mejoran significativamente con SMOTE (ej: Random Forest, Decision Tree)\n",
    "   - Otros funcionan mejor sin balanceo (ej: XGBoost, posiblemente por manejo interno de desbalanceo)\n",
    "   - El nivel óptimo de SMOTE depende del algoritmo\n",
    "\n",
    "2. **Trade-offs observados:**\n",
    "   - SMOTE generalmente mejora **Recall** (detecta más compradores)\n",
    "   - Puede reducir **Precision** (más falsos positivos)\n",
    "   - El **F1-Score** captura el balance entre ambos\n",
    "\n",
    "3. **Consideraciones prácticas:**\n",
    "   - Tiempo de entrenamiento aumenta con SMOTE (más datos)\n",
    "   - Modelos ensemble (RF, XGBoost) son más robustos\n",
    "   - Redes neuronales (MLP) pueden requerir más datos o ajuste fino\n",
    "\n",
    "**✅ Recomendación final:**\n",
    "El modelo óptimo identificado será usado en la siguiente fase para optimización de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4a1a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar top 3 configuraciones globales\n",
    "todas_configuraciones = []\n",
    "\n",
    "# Baseline\n",
    "for model_name in baseline_results.keys():\n",
    "    todas_configuraciones.append({\n",
    "        'Configuración': 'Baseline',\n",
    "        'Modelo': model_name,\n",
    "        'F1-Score': baseline_results[model_name]['F1-Score'],\n",
    "        'Recall': baseline_results[model_name]['Recall'],\n",
    "        'Precision': baseline_results[model_name]['Precision'],\n",
    "        'ROC-AUC': baseline_results[model_name]['ROC-AUC'],\n",
    "        'Accuracy': baseline_results[model_name]['Accuracy'],\n",
    "        'Tiempo (s)': baseline_results[model_name]['Training Time (s)']\n",
    "    })\n",
    "\n",
    "# SMOTE\n",
    "for smote_level in ['SMOTE 5%', 'SMOTE 10%', 'SMOTE 15%']:\n",
    "    for model_name in smote_results[smote_level].keys():\n",
    "        todas_configuraciones.append({\n",
    "            'Configuración': smote_level,\n",
    "            'Modelo': model_name,\n",
    "            'F1-Score': smote_results[smote_level][model_name]['F1-Score'],\n",
    "            'Recall': smote_results[smote_level][model_name]['Recall'],\n",
    "            'Precision': smote_results[smote_level][model_name]['Precision'],\n",
    "            'ROC-AUC': smote_results[smote_level][model_name]['ROC-AUC'],\n",
    "            'Accuracy': smote_results[smote_level][model_name]['Accuracy'],\n",
    "            'Tiempo (s)': smote_results[smote_level][model_name]['Training Time (s)']\n",
    "        })\n",
    "\n",
    "df_todas = pd.DataFrame(todas_configuraciones)\n",
    "top_3 = df_todas.nlargest(3, 'F1-Score')\n",
    "\n",
    "print(\"\\n\" + \"🥇🥈🥉\" * 30)\n",
    "print(\"TOP 3 MEJORES CONFIGURACIONES (Modelo + SMOTE)\")\n",
    "print(\"🥇🥈🥉\" * 30)\n",
    "print(top_3.round(4).to_string(index=False))\n",
    "\n",
    "# Análisis comparativo del top 3\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ANÁLISIS COMPARATIVO DEL TOP 3\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for idx, (i, row) in enumerate(top_3.iterrows(), 1):\n",
    "    medalla = [\"🥇\", \"🥈\", \"🥉\"][idx-1]\n",
    "    print(f\"\\n{medalla} PUESTO {idx}: {row['Modelo']} ({row['Configuración']})\")\n",
    "    print(f\"  ├─ F1-Score:  {row['F1-Score']:.4f}\")\n",
    "    print(f\"  ├─ Recall:    {row['Recall']:.4f}\")\n",
    "    print(f\"  ├─ Precision: {row['Precision']:.4f}\")\n",
    "    print(f\"  ├─ ROC-AUC:   {row['ROC-AUC']:.4f}\")\n",
    "    print(f\"  ├─ Accuracy:  {row['Accuracy']:.4f}\")\n",
    "    print(f\"  └─ Tiempo:    {row['Tiempo (s)']:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a430095",
   "metadata": {},
   "source": [
    "### 3.3.5: Top 3 Modelos - Comparación Detallada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c49928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar cómo cada modelo se comporta con diferentes niveles de SMOTE\n",
    "print(\"\\n\" + \"=\" * 120)\n",
    "print(\"EVOLUCIÓN DE F1-SCORE POR MODELO SEGÚN NIVEL DE SMOTE\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "# Obtener lista de modelos\n",
    "all_models = list(baseline_results.keys())\n",
    "\n",
    "evolution_data = []\n",
    "\n",
    "for model_name in all_models:\n",
    "    row = {\n",
    "        'Modelo': model_name,\n",
    "        'Baseline': baseline_results[model_name]['F1-Score'],\n",
    "        'SMOTE 5%': smote_results['SMOTE 5%'][model_name]['F1-Score'],\n",
    "        'SMOTE 10%': smote_results['SMOTE 10%'][model_name]['F1-Score'],\n",
    "        'SMOTE 15%': smote_results['SMOTE 15%'][model_name]['F1-Score']\n",
    "    }\n",
    "    \n",
    "    # Calcular cambio respecto a baseline\n",
    "    row['Δ Max (%)'] = ((max(row['SMOTE 5%'], row['SMOTE 10%'], row['SMOTE 15%']) - row['Baseline']) / row['Baseline'] * 100)\n",
    "    \n",
    "    evolution_data.append(row)\n",
    "\n",
    "df_evolution = pd.DataFrame(evolution_data)\n",
    "df_evolution = df_evolution.sort_values('Baseline', ascending=False)\n",
    "\n",
    "print(df_evolution.round(4).to_string(index=False))\n",
    "\n",
    "# Identificar modelos que mejoran con SMOTE\n",
    "print(\"\\n📊 ANÁLISIS:\")\n",
    "mejoran_con_smote = df_evolution[df_evolution['Δ Max (%)'] > 0].sort_values('Δ Max (%)', ascending=False)\n",
    "empeoran_con_smote = df_evolution[df_evolution['Δ Max (%)'] <= 0].sort_values('Δ Max (%)')\n",
    "\n",
    "print(f\"\\n✅ Modelos que MEJORAN con SMOTE ({len(mejoran_con_smote)}):\")\n",
    "for idx, row in mejoran_con_smote.iterrows():\n",
    "    print(f\"  • {row['Modelo']}: +{row['Δ Max (%)']:.2f}% mejora\")\n",
    "\n",
    "print(f\"\\n❌ Modelos que NO mejoran con SMOTE ({len(empeoran_con_smote)}):\")\n",
    "for idx, row in empeoran_con_smote.iterrows():\n",
    "    print(f\"  • {row['Modelo']}: {row['Δ Max (%)']:.2f}% cambio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b24ad5",
   "metadata": {},
   "source": [
    "### 3.3.4: Análisis del Efecto de SMOTE por Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8373eaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla comparativa de los ganadores\n",
    "ganadores = []\n",
    "\n",
    "# Agregar baseline\n",
    "ganadores.append({\n",
    "    'Configuración': 'Baseline (Sin SMOTE)',\n",
    "    'Modelo': best_baseline,\n",
    "    'F1-Score': baseline_df.loc[best_baseline, 'F1-Score'],\n",
    "    'Recall': baseline_df.loc[best_baseline, 'Recall'],\n",
    "    'Precision': baseline_df.loc[best_baseline, 'Precision'],\n",
    "    'ROC-AUC': baseline_df.loc[best_baseline, 'ROC-AUC'],\n",
    "    'Tiempo (s)': baseline_df.loc[best_baseline, 'Training Time (s)']\n",
    "})\n",
    "\n",
    "# Agregar cada nivel de SMOTE\n",
    "for smote_level, data in best_by_smote.items():\n",
    "    ganadores.append({\n",
    "        'Configuración': smote_level,\n",
    "        'Modelo': data['modelo'],\n",
    "        'F1-Score': data['f1'],\n",
    "        'Recall': data['recall'],\n",
    "        'Precision': data['precision'],\n",
    "        'ROC-AUC': data['roc_auc'],\n",
    "        'Tiempo (s)': data['tiempo']\n",
    "    })\n",
    "\n",
    "df_ganadores = pd.DataFrame(ganadores)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 120)\n",
    "print(\"COMPARACIÓN DE MODELOS GANADORES POR CONFIGURACIÓN\")\n",
    "print(\"=\" * 120)\n",
    "print(df_ganadores.round(4).to_string(index=False))\n",
    "\n",
    "# Identificar el ganador absoluto\n",
    "mejor_absoluto_idx = df_ganadores['F1-Score'].idxmax()\n",
    "mejor_config = df_ganadores.loc[mejor_absoluto_idx, 'Configuración']\n",
    "mejor_modelo = df_ganadores.loc[mejor_absoluto_idx, 'Modelo']\n",
    "\n",
    "print(\"\\n\" + \"🎯\" * 60)\n",
    "print(\"MODELO ÓPTIMO GENERAL\")\n",
    "print(\"🎯\" * 60)\n",
    "print(f\"Configuración: {mejor_config}\")\n",
    "print(f\"Modelo: {mejor_modelo}\")\n",
    "print(f\"F1-Score: {df_ganadores.loc[mejor_absoluto_idx, 'F1-Score']:.4f}\")\n",
    "print(f\"Recall: {df_ganadores.loc[mejor_absoluto_idx, 'Recall']:.4f}\")\n",
    "print(f\"Precision: {df_ganadores.loc[mejor_absoluto_idx, 'Precision']:.4f}\")\n",
    "print(f\"ROC-AUC: {df_ganadores.loc[mejor_absoluto_idx, 'ROC-AUC']:.4f}\")\n",
    "print(f\"Tiempo de entrenamiento: {df_ganadores.loc[mejor_absoluto_idx, 'Tiempo (s)']:.2f}s\")\n",
    "print(\"🎯\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cfd400",
   "metadata": {},
   "source": [
    "### 3.3.3: Comparación de los Ganadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b657b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar cada nivel de SMOTE\n",
    "best_by_smote = {}\n",
    "\n",
    "for smote_level in ['SMOTE 5%', 'SMOTE 10%', 'SMOTE 15%']:\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(f\"RESULTADOS {smote_level} - Ordenados por F1-Score\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # Crear DataFrame para este nivel\n",
    "    smote_df = pd.DataFrame(smote_results[smote_level]).T\n",
    "    smote_df = smote_df.sort_values('F1-Score', ascending=False)\n",
    "    \n",
    "    print(smote_df.round(4).to_string())\n",
    "    \n",
    "    # Identificar el mejor\n",
    "    best_model = smote_df.index[0]\n",
    "    best_by_smote[smote_level] = {\n",
    "        'modelo': best_model,\n",
    "        'f1': smote_df.loc[best_model, 'F1-Score'],\n",
    "        'recall': smote_df.loc[best_model, 'Recall'],\n",
    "        'precision': smote_df.loc[best_model, 'Precision'],\n",
    "        'roc_auc': smote_df.loc[best_model, 'ROC-AUC'],\n",
    "        'tiempo': smote_df.loc[best_model, 'Training Time (s)']\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n🏆 Mejor modelo {smote_level}: {best_model}\")\n",
    "    print(f\"  • F1-Score: {best_by_smote[smote_level]['f1']:.4f}\")\n",
    "    print(f\"  • Recall: {best_by_smote[smote_level]['recall']:.4f}\")\n",
    "    print(f\"  • Precision: {best_by_smote[smote_level]['precision']:.4f}\")\n",
    "    print(f\"  • ROC-AUC: {best_by_smote[smote_level]['roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e165c8",
   "metadata": {},
   "source": [
    "### 3.3.2: Mejor Modelo por Nivel de SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a2063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con resultados baseline\n",
    "baseline_df = pd.DataFrame(baseline_results).T\n",
    "baseline_df = baseline_df[['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC', 'Training Time (s)']]\n",
    "baseline_df = baseline_df.sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"RESULTADOS BASELINE (SIN SMOTE) - Ordenados por F1-Score\")\n",
    "print(\"=\" * 100)\n",
    "print(baseline_df.round(4).to_string())\n",
    "\n",
    "# Identificar el mejor\n",
    "best_baseline = baseline_df.index[0]\n",
    "print(\"\\n\" + \"🏆\" * 50)\n",
    "print(f\"MEJOR MODELO BASELINE: {best_baseline}\")\n",
    "print(f\"  • F1-Score: {baseline_df.loc[best_baseline, 'F1-Score']:.4f}\")\n",
    "print(f\"  • Recall: {baseline_df.loc[best_baseline, 'Recall']:.4f}\")\n",
    "print(f\"  • Precision: {baseline_df.loc[best_baseline, 'Precision']:.4f}\")\n",
    "print(f\"  • ROC-AUC: {baseline_df.loc[best_baseline, 'ROC-AUC']:.4f}\")\n",
    "print(f\"  • Tiempo de entrenamiento: {baseline_df.loc[best_baseline, 'Training Time (s)']:.2f}s\")\n",
    "print(\"🏆\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2cc2b1",
   "metadata": {},
   "source": [
    "### 3.3.1: Mejor Modelo Baseline (Sin SMOTE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
